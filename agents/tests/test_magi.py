#!/usr/bin/env python3
"""
MAGIã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ†é¡ãƒ†ã‚¹ãƒˆ

AgentCore Runtimeã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã€
å„è³¢è€…ã¨SOLOMON Judgeã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å€‹åˆ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã™ã€‚

å®Ÿè¡Œæ–¹æ³•:
    cd agents/tests
    python test_streaming_classification.py

å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:
    - streaming_output/caspar_stream.txt
    - streaming_output/balthasar_stream.txt
    - streaming_output/melchior_stream.txt
    - streaming_output/solomon_stream.txt
    - streaming_output/full_stream.json (å…¨ã‚¤ãƒ™ãƒ³ãƒˆ)
    - streaming_output/summary.txt (ã‚µãƒãƒªãƒ¼)
"""

import asyncio
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ ï¼ˆshared ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ï¼‰
sys.path.insert(0, str(Path(__file__).parent.parent))

# AWS SDK
import boto3
from botocore.config import Config
from botocore.auth import SigV4Auth
from botocore.awsrequest import AWSRequest

# HTTPã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨
import requests


class StreamingClassificationTester:
    """
    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ†é¡ãƒ†ã‚¹ã‚¿ãƒ¼
    
    AgentCore Runtimeã‹ã‚‰ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã€
    å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã”ã¨ã«ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†é¡ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚
    """
    
    def __init__(self, agent_runtime_arn: str, region: str = "ap-northeast-1", verbose: bool = True):
        """
        åˆæœŸåŒ–
        
        Args:
            agent_runtime_arn: AgentCore Runtimeã®ARN
            region: AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³
            verbose: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚³ãƒ³ã‚½ãƒ¼ãƒ«è¡¨ç¤ºã‚’æœ‰åŠ¹ã«ã™ã‚‹
        """
        self.agent_runtime_arn = agent_runtime_arn
        self.region = region
        self.verbose = verbose
        
        # Boto3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å»¶é•·ï¼‰
        config = Config(
            region_name=region,
            signature_version='v4',
            retries={'max_attempts': 3, 'mode': 'standard'},
            read_timeout=300,  # 5åˆ†ã«å»¶é•·ï¼ˆMAGIå®Ÿè¡Œæ™‚é–“ã‚’è€ƒæ…®ï¼‰
            connect_timeout=10
        )
        self.client = boto3.client('bedrock-agentcore', config=config)
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.output_dir = Path("streaming_output")
        self.output_dir.mkdir(exist_ok=True)
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ åé›†ç”¨
        self.streams = {
            "caspar": [],
            "balthasar": [],
            "melchior": [],
            "solomon": []
        }
        
        # å…¨ã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²
        self.all_events = []
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            "total_events": 0,
            "events_by_type": {},
            "chunks_by_agent": {
                "caspar": 0,
                "balthasar": 0,
                "melchior": 0,
                "solomon": 0
            },
            "start_time": None,
            "end_time": None
        }
    
    async def test_streaming(self, question: str):
        """
        ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        
        Args:
            question: ãƒ†ã‚¹ãƒˆè³ªå•
        """
        print("=" * 80)
        print("MAGI Streaming Classification Test")
        print("=" * 80)
        print(f"Question: {question}")
        print(f"Agent ARN: {self.agent_runtime_arn}")
        print(f"Output Directory: {self.output_dir.absolute()}")
        print("=" * 80)
        print()
        
        self.stats["start_time"] = datetime.now()
        
        try:
            # AgentCore Runtimeã‚’å‘¼ã³å‡ºã—
            print("ğŸ“¡ Invoking AgentCore Runtime...")
            
            payload = json.dumps({"question": question})
            
            # UUIDã‚’ä½¿ç”¨ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆï¼ˆæœ€å°33æ–‡å­—å¿…è¦ï¼‰
            import uuid
            session_id = str(uuid.uuid4())
            
            response = self.client.invoke_agent_runtime(
                agentRuntimeArn=self.agent_runtime_arn,
                runtimeSessionId=session_id,
                payload=payload.encode('utf-8')
            )
            
            print("âœ… Connection established, receiving stream...")
            print()
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
            if 'response' in response:
                event_stream = response['response']
                
                # ã‚¤ãƒ™ãƒ³ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å‡¦ç†
                async for parsed_event in self._process_event_stream(event_stream):
                    self._handle_event(parsed_event)
            
            self.stats["end_time"] = datetime.now()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            self._save_streams()
            
            # ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
            self._print_summary()
            
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()
    
    async def _process_event_stream(self, event_stream):
        """
        ã‚¤ãƒ™ãƒ³ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å‡¦ç†ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
        
        Args:
            event_stream: Boto3ã®EventStreamã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            
        Yields:
            Dict[str, Any]: ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆ
        """
        buffer = ""
        chunk_count = 0
        
        try:
            # EventStreamã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å®Ÿéš›ã®å‹ã‚’ç¢ºèª
            stream_type = type(event_stream).__name__
            
            if self.verbose:
                print(f"ğŸ” Processing stream type: {stream_type}")
                print(f"ğŸ” Stream methods: {[m for m in dir(event_stream) if not m.startswith('_')]}")
                print()
            
            # StreamingBodyã®å ´åˆã€iter_lines()ã‚’ä½¿ç”¨
            if hasattr(event_stream, 'iter_lines'):
                if self.verbose:
                    print("Using iter_lines() for streaming...")
                    print()
                
                loop = asyncio.get_event_loop()
                
                # iter_lines()ã‚’éåŒæœŸã§å‡¦ç†
                for line in event_stream.iter_lines():
                    # éåŒæœŸå‡¦ç†ã‚’æŒŸã‚€
                    await asyncio.sleep(0)
                    
                    chunk_count += 1
                    
                    if line:
                        # è¡Œãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
                        text = line.decode('utf-8') if isinstance(line, bytes) else line
                        buffer += text + '\n'
                    else:
                        # ç©ºè¡Œã¯ã‚¤ãƒ™ãƒ³ãƒˆåŒºåˆ‡ã‚Š
                        if buffer.strip():
                            parsed_event = self._parse_sse_event(buffer)
                            if parsed_event:
                                yield parsed_event
                                await asyncio.sleep(0)
                            buffer = ""
            
            # iter_chunks()ã‚’ä½¿ç”¨ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            elif hasattr(event_stream, 'iter_chunks'):
                if self.verbose:
                    print("Using iter_chunks() for streaming...")
                    print()
                
                for chunk_data in event_stream.iter_chunks(chunk_size=1024):
                    # éåŒæœŸå‡¦ç†ã‚’æŒŸã‚€
                    await asyncio.sleep(0)
                    
                    chunk_count += 1
                    
                    # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
                    text = chunk_data.decode('utf-8', errors='ignore') if isinstance(chunk_data, bytes) else chunk_data
                    buffer += text
                    
                    # SSEã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆå³åº§ã«å‡¦ç†ï¼‰
                    while '\n\n' in buffer:
                        event_text, buffer = buffer.split('\n\n', 1)
                        
                        parsed_event = self._parse_sse_event(event_text)
                        if parsed_event:
                            yield parsed_event
                            await asyncio.sleep(0)
            
            # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã¨ã—ã¦å‡¦ç†ï¼ˆæœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            else:
                if self.verbose:
                    print("Using iterator for streaming...")
                    print()
                
                for chunk_data in event_stream:
                    # éåŒæœŸå‡¦ç†ã‚’æŒŸã‚€
                    await asyncio.sleep(0)
                    
                    chunk_count += 1
                    
                    # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
                    if isinstance(chunk_data, dict) and 'chunk' in chunk_data:
                        chunk = chunk_data['chunk']
                        
                        # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
                        if 'bytes' in chunk:
                            text = chunk['bytes'].decode('utf-8', errors='ignore')
                            buffer += text
                            
                            # SSEã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆå³åº§ã«å‡¦ç†ï¼‰
                            while '\n\n' in buffer:
                                event_text, buffer = buffer.split('\n\n', 1)
                                
                                parsed_event = self._parse_sse_event(event_text)
                                if parsed_event:
                                    yield parsed_event
                                    await asyncio.sleep(0)
                    elif isinstance(chunk_data, bytes):
                        # ç›´æ¥ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã®å ´åˆ
                        text = chunk_data.decode('utf-8', errors='ignore')
                        buffer += text
                        
                        while '\n\n' in buffer:
                            event_text, buffer = buffer.split('\n\n', 1)
                            
                            parsed_event = self._parse_sse_event(event_text)
                            if parsed_event:
                                yield parsed_event
                                await asyncio.sleep(0)
            
            # æ®‹ã‚Šã®ãƒãƒƒãƒ•ã‚¡ã‚’å‡¦ç†
            if buffer.strip():
                parsed_event = self._parse_sse_event(buffer)
                if parsed_event:
                    yield parsed_event
            
            if self.verbose:
                print(f"\nğŸ“¦ Total chunks processed: {chunk_count}")
                    
        except Exception as e:
            print(f"âš ï¸  Stream processing error: {e}")
            import traceback
            traceback.print_exc()
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: read()ãƒ¡ã‚½ãƒƒãƒ‰ã§ä¸€æ‹¬èª­ã¿è¾¼ã¿
            try:
                if self.verbose:
                    print("âš ï¸  Falling back to read() method...")
                
                data = event_stream.read()
                text = data.decode('utf-8') if isinstance(data, bytes) else data
                
                # SSEã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹
                for event_text in text.split('\n\n'):
                    if event_text.strip():
                        parsed_event = self._parse_sse_event(event_text)
                        if parsed_event:
                            yield parsed_event
                            await asyncio.sleep(0)
            except Exception as fallback_error:
                print(f"âš ï¸  Fallback also failed: {fallback_error}")
    
    def _parse_sse_event(self, event_text: str) -> Dict[str, Any]:
        """
        SSEã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹
        
        Args:
            event_text: SSEã‚¤ãƒ™ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            Dict[str, Any]: ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆ
        """
        lines = event_text.strip().split('\n')
        
        for line in lines:
            if line.startswith('data:'):
                data_text = line[5:].strip()
                try:
                    parsed = json.loads(data_text)
                    # æ–°ã—ã„å½¢å¼: {"type": "...", "data": {...}}
                    if isinstance(parsed, dict) and 'type' in parsed and 'data' in parsed:
                        return {
                            "type": parsed['type'],
                            "data": parsed['data'],
                            "timestamp": datetime.now().isoformat()
                        }
                    # å¤ã„å½¢å¼ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
                    return {
                        "type": "unknown",
                        "data": parsed,
                        "timestamp": datetime.now().isoformat()
                    }
                except json.JSONDecodeError:
                    pass
        
        return None
    
    def _handle_event(self, event: Dict[str, Any]):
        """
        ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†
        
        Args:
            event: ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿
        """
        self.stats["total_events"] += 1
        
        event_type = event.get("type")
        event_data = event.get("data", {})
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—çµ±è¨ˆ
        self.stats["events_by_type"][event_type] = \
            self.stats["events_by_type"].get(event_type, 0) + 1
        
        # å…¨ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²
        self.all_events.append(event)
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã”ã¨ã®å‡¦ç†
        if event_type == "start":
            if self.verbose:
                print(f"ğŸš€ MAGI Decision Process Started")
                print(f"   Trace ID: {event_data.get('trace_id')}")
                print()
        
        elif event_type == "sage_start":
            agent_id = event_data.get("agent_id")
            if self.verbose:
                print(f"ğŸ¤– {agent_id.upper()} started thinking...")
        
        elif event_type == "sage_thinking":
            agent_id = event_data.get("agent_id")
            chunk = event_data.get("chunk", "")
            
            # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
            if self.verbose:
                print(f"   ğŸ’­ {agent_id.upper()} thinking: {chunk}", end='', flush=True)
        
        elif event_type == "sage_chunk":
            agent_id = event_data.get("agent_id")
            chunk = event_data.get("chunk", "")
            
            # ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
            self.streams[agent_id].append(chunk)
            self.stats["chunks_by_agent"][agent_id] += 1
            
            if self.verbose:
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºï¼ˆå…¨æ–‡ï¼‰
                print(f"   ğŸ’­ {agent_id.upper()}: {chunk}")
        
        elif event_type == "sage_complete":
            agent_id = event_data.get("agent_id")
            decision = event_data.get("decision")
            confidence = event_data.get("confidence")
            reasoning = event_data.get("reasoning", "")
            
            if self.verbose:
                print(f"\n   âœ… {agent_id.upper()}: {decision} (confidence: {confidence:.2f})")
                print(f"      Reasoning: {reasoning}")
                print()
        
        elif event_type == "sage_error":
            agent_id = event_data.get("agent_id")
            error = event_data.get("error")
            if self.verbose:
                print(f"   âŒ {agent_id.upper()} error: {error}")
                print()
        
        elif event_type == "judge_start":
            if self.verbose:
                print(f"\nâš–ï¸  SOLOMON Judge started evaluation...")
                print()
        
        elif event_type == "judge_thinking":
            chunk = event_data.get("chunk", "")
            
            # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
            if self.verbose:
                print(f"   ğŸ’­ SOLOMON thinking: {chunk}", end='', flush=True)
        
        elif event_type == "judge_chunk":
            chunk = event_data.get("chunk", "")
            
            # SOLOMONã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
            self.streams["solomon"].append(chunk)
            self.stats["chunks_by_agent"]["solomon"] += 1
            
            # é€²æ—è¡¨ç¤º
            preview = chunk[:50].replace('\n', ' ')
            print(f"   ğŸ’­ SOLOMON: {preview}{'...' if len(chunk) > 50 else ''}")
        
        elif event_type == "judge_complete":
            final_decision = event_data.get("final_decision")
            confidence = event_data.get("confidence")
            execution_time = event_data.get("execution_time")
            
            print(f"   âœ… SOLOMON: {final_decision} (confidence: {confidence:.2f}, {execution_time}ms)")
            print()
        
        elif event_type == "complete":
            final_decision = event_data.get("final_decision")
            voting_result = event_data.get("voting_result", {})
            total_time = event_data.get("total_execution_time")
            
            print(f"ğŸ‰ MAGI Decision Complete!")
            print(f"   Final Decision: {final_decision}")
            print(f"   Voting: {voting_result.get('approved')}å¯æ±º / {voting_result.get('rejected')}å¦æ±º")
            print(f"   Total Time: {total_time}ms")
            print()
        
        elif event_type == "error":
            error = event_data.get("error")
            print(f"âŒ Error: {error}")
            print()
    
    def _save_streams(self):
        """
        ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        """
        print("=" * 80)
        print("ğŸ’¾ Saving streams to files...")
        print("=" * 80)
        
        # å„è³¢è€…ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä¿å­˜
        for agent_id, chunks in self.streams.items():
            if chunks:
                filename = self.output_dir / f"{agent_id}_stream.txt"
                
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(f"# {agent_id.upper()} Stream\n")
                    f.write(f"# Generated: {datetime.now().isoformat()}\n")
                    f.write(f"# Total Chunks: {len(chunks)}\n")
                    f.write("=" * 80 + "\n\n")
                    
                    full_text = ''.join(chunks)
                    f.write(full_text)
                
                print(f"âœ… Saved {agent_id}_stream.txt ({len(chunks)} chunks, {len(full_text)} chars)")
        
        # å…¨ã‚¤ãƒ™ãƒ³ãƒˆã‚’JSONã§ä¿å­˜
        events_file = self.output_dir / "full_stream.json"
        with open(events_file, 'w', encoding='utf-8') as f:
            json.dump(self.all_events, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Saved full_stream.json ({len(self.all_events)} events)")
        
        # ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜
        self._save_summary()
        
        print()
    
    def _save_summary(self):
        """
        ã‚µãƒãƒªãƒ¼ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        """
        summary_file = self.output_dir / "summary.txt"
        
        duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("# MAGI Streaming Classification Test Summary\n")
            f.write("=" * 80 + "\n\n")
            
            f.write(f"Test Time: {self.stats['start_time'].isoformat()}\n")
            f.write(f"Duration: {duration:.2f} seconds\n")
            f.write(f"Total Events: {self.stats['total_events']}\n\n")
            
            f.write("## Events by Type\n")
            for event_type, count in sorted(self.stats["events_by_type"].items()):
                f.write(f"  {event_type}: {count}\n")
            f.write("\n")
            
            f.write("## Chunks by Agent\n")
            for agent_id, count in self.stats["chunks_by_agent"].items():
                f.write(f"  {agent_id}: {count} chunks\n")
            f.write("\n")
            
            f.write("## Stream Sizes\n")
            for agent_id, chunks in self.streams.items():
                if chunks:
                    total_chars = len(''.join(chunks))
                    f.write(f"  {agent_id}: {total_chars} characters\n")
            f.write("\n")
            
            f.write("## Files Generated\n")
            for agent_id in self.streams.keys():
                if self.streams[agent_id]:
                    f.write(f"  - {agent_id}_stream.txt\n")
            f.write(f"  - full_stream.json\n")
            f.write(f"  - summary.txt\n")
        
        print(f"âœ… Saved summary.txt")
    
    def _print_summary(self):
        """
        ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        """
        print("=" * 80)
        print("ğŸ“Š Test Summary")
        print("=" * 80)
        
        duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()
        
        print(f"Duration: {duration:.2f} seconds")
        print(f"Total Events: {self.stats['total_events']}")
        print()
        
        print("Events by Type:")
        for event_type, count in sorted(self.stats["events_by_type"].items()):
            print(f"  {event_type}: {count}")
        print()
        
        print("Chunks by Agent:")
        for agent_id, count in self.stats["chunks_by_agent"].items():
            print(f"  {agent_id}: {count} chunks")
        print()
        
        print("Stream Sizes:")
        for agent_id, chunks in self.streams.items():
            if chunks:
                total_chars = len(''.join(chunks))
                print(f"  {agent_id}: {total_chars} characters")
        print()
        
        print(f"Output Directory: {self.output_dir.absolute()}")
        print("=" * 80)


async def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    # AgentCore Runtimeã®ARNï¼ˆç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ç›´æ¥æŒ‡å®šï¼‰
    agent_runtime_arn = os.environ.get(
        "MAGI_AGENT_ARN",
        "arn:aws:bedrock-agentcore:ap-northeast-1:262152767881:runtime/magi_agent-4ORNam2cHb"
    )
    
    # ãƒ†ã‚¹ãƒˆè³ªå•
    test_question = "æ–°ã—ã„AIã‚·ã‚¹ãƒ†ãƒ ã‚’å…¨ç¤¾ã«å°å…¥ã™ã¹ãã‹ï¼Ÿã‚³ã‚¹ãƒˆå‰Šæ¸›ã¨åŠ¹ç‡åŒ–ãŒæœŸå¾…ã•ã‚Œã‚‹ãŒã€å¾“æ¥­å“¡ã®åç™ºã‚‚äºˆæƒ³ã•ã‚Œã‚‹ã€‚"
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡ï¼‰
    # verbose=True ã§3è³¢è€…ã®ä¸¦åˆ—ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
    verbose = os.environ.get('DEBUG_STREAMING', 'true').lower() == 'true'
    
    # ãƒ†ã‚¹ã‚¿ãƒ¼åˆæœŸåŒ–
    tester = StreamingClassificationTester(agent_runtime_arn, verbose=verbose)
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    await tester.test_streaming(test_question)


if __name__ == "__main__":
    # éåŒæœŸå®Ÿè¡Œ
    asyncio.run(main())
