#!/usr/bin/env python3
"""
MAGIã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ†é¡ãƒ†ã‚¹ãƒˆ - ä¸¦åˆ—å‡¦ç†ç‰ˆ

ğŸš€ PARALLEL STREAMING TEST âš¡
==============================

âœ… çœŸã®ä¸¦åˆ—å®Ÿè¡Œãƒ†ã‚¹ãƒˆ: 3è³¢è€…ãŒåŒæ™‚ã«æ€è€ƒãƒ»å¿œç­”
âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š: é€æ¬¡ç‰ˆã¨ã®å®Ÿè¡Œæ™‚é–“æ¯”è¼ƒ
âœ… å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: streaming_output_parallel/ ã«å®Œå…¨ãªå®Ÿè¡Œè¨˜éŒ²ã‚’ä¿å­˜

ã“ã®ãƒ†ã‚¹ãƒˆã¯ä¸¦åˆ—å‡¦ç†ç‰ˆmagi_agent.pyã®å‹•ä½œç¢ºèªç”¨ã§ã™ã€‚

å®Ÿè¡Œæ–¹æ³•:
    cd agents/tests
    python test_parallel.py

æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„:
    - å®Ÿè¡Œæ™‚é–“: 30ç§’ â†’ 10ç§’ï¼ˆ3å€é«˜é€ŸåŒ–ï¼‰
    - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§: 3è³¢è€…ã®ä¸¦åˆ—æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹è¡¨ç¤º
    - ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡: CPUãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æœ€é©åˆ©ç”¨

æ¯”è¼ƒæ–¹æ³•:
    # é€æ¬¡ç‰ˆãƒ†ã‚¹ãƒˆ
    python test_magi2.py
    
    # ä¸¦åˆ—ç‰ˆãƒ†ã‚¹ãƒˆ
    python test_parallel.py
    
    # å®Ÿè¡Œæ™‚é–“æ¯”è¼ƒ
    diff streaming_output_phase2/summary.txt streaming_output_parallel/summary.txt

ç’°å¢ƒå¤‰æ•°:
    MAGI_AGENT_ARN - AgentCore Runtimeã®ARN
    AWS_REGION - AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ap-northeast-1ï¼‰
    DEBUG_STREAMING - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã®æœ‰åŠ¹åŒ–

å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:
    - agents/tests/streaming_output_parallel/caspar_stream.txt
    - agents/tests/streaming_output_parallel/balthasar_stream.txt
    - agents/tests/streaming_output_parallel/melchior_stream.txt
    - agents/tests/streaming_output_parallel/solomon_stream.txt
    - agents/tests/streaming_output_parallel/full_stream.json (å…¨ã‚¤ãƒ™ãƒ³ãƒˆ)
    - agents/tests/streaming_output_parallel/full_response_ordered.txt (é †åºä»˜ãå…¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹)
    - agents/tests/streaming_output_parallel/summary.txt (ã‚µãƒãƒªãƒ¼)
    - agents/tests/streaming_output_parallel/performance_comparison.txt (ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ)
"""

import asyncio
import json
import os
import sys
import urllib.parse
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List

# HTTPã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨
import requests
from requests_aws4auth import AWS4Auth

# AWSèªè¨¼æƒ…å ±å–å¾—ç”¨
import boto3


class ParallelStreamingTester:
    """
    ä¸¦åˆ—ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ã‚¿ãƒ¼
    
    ä¸¦åˆ—å‡¦ç†ç‰ˆmagi_agent.pyã®å‹•ä½œç¢ºèªã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šã‚’è¡Œã„ã¾ã™ã€‚
    """
    
    def __init__(self, agent_arn: str = None, region: str = "ap-northeast-1", verbose: bool = True):
        """
        åˆæœŸåŒ–
        
        Args:
            agent_arn: AgentCore Runtimeã®ARNï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•å–å¾—å¯èƒ½ï¼‰
            region: AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³
            verbose: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚³ãƒ³ã‚½ãƒ¼ãƒ«è¡¨ç¤ºã‚’æœ‰åŠ¹ã«ã™ã‚‹
        """
        self.agent_arn = agent_arn or os.environ.get('MAGI_AGENT_ARN')
        self.region = region
        self.verbose = verbose
        
        if not self.agent_arn:
            raise ValueError("MAGI_AGENT_ARN environment variable is required")
        
        # AgentCore Runtimeã®URLã‚’æ§‹ç¯‰
        self.runtime_url = self._build_runtime_url()
        
        # AWSèªè¨¼æƒ…å ±å–å¾—
        session = boto3.Session()
        credentials = session.get_credentials()
        
        # AWS4Authè¨­å®š
        self.auth = AWS4Auth(
            credentials.access_key,
            credentials.secret_key,
            self.region,
            'bedrock-agentcore',
            session_token=credentials.token
        )
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆä¸¦åˆ—ç‰ˆå°‚ç”¨ï¼‰
        self.output_dir = Path(__file__).parent / "streaming_output_parallel"
        self.output_dir.mkdir(exist_ok=True)
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ åé›†ç”¨
        self.streams = {
            "caspar": [],
            "balthasar": [],
            "melchior": [],
            "solomon": []
        }
        
        # å…¨ã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²
        self.all_events = []
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            "total_events": 0,
            "events_by_type": {},
            "chunks_by_agent": {
                "caspar": 0,
                "balthasar": 0,
                "melchior": 0,
                "solomon": 0
            },
            "start_time": None,
            "end_time": None,
            "first_sage_start": None,
            "last_sage_complete": None,
            "parallel_execution_time": None
        }
    
    def _build_runtime_url(self) -> str:
        """
        AgentCore Runtimeã®URLã‚’æ§‹ç¯‰
        
        Returns:
            str: AgentCore Runtimeã®URL
        """
        # ARNã‚’URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        escaped_arn = urllib.parse.quote(self.agent_arn, safe='')
        
        # URLæ§‹ç¯‰
        url = f"https://bedrock-agentcore.{self.region}.amazonaws.com/runtimes/{escaped_arn}/invocations"
        
        if self.verbose:
            print(f"ğŸ”— Runtime URL: {url}")
        
        return url
    
    def test_streaming(self, question: str):
        """
        ä¸¦åˆ—ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        
        Args:
            question: ãƒ†ã‚¹ãƒˆè³ªå•
        """
        print("=" * 80)
        print("ğŸš€ MAGI Parallel Streaming Test")
        print("=" * 80)
        print(f"Question: {question}")
        print(f"Runtime URL: {self.runtime_url}")
        print(f"Output Directory: {self.output_dir.absolute()}")
        print("=" * 80)
        print()
        
        self.stats["start_time"] = datetime.now()
        
        try:
            # AgentCore Runtimeã«HTTP POSTãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
            print("ğŸ“¡ Sending HTTP POST to AgentCore Runtime (Parallel Version)...")
            
            payload = {"question": question}
            payload_json = json.dumps(payload)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDç”Ÿæˆï¼ˆ33æ–‡å­—ä»¥ä¸Šå¿…è¦ï¼‰
            import uuid
            session_id = f"parallel-{int(datetime.now().timestamp())}-{uuid.uuid4().hex}"
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼æº–å‚™
            headers = {
                'Content-Type': 'application/json',
                'Accept': 'text/event-stream',
                'X-Amzn-Bedrock-AgentCore-Runtime-Session-Id': session_id,
                'X-Amzn-Trace-Id': f"trace-parallel-{int(datetime.now().timestamp())}"
            }
            
            if self.verbose:
                print(f"ğŸ“ Session ID: {session_id}")
                print(f"ğŸ” Using AWS4Auth for SigV4 signing")
                print(f"âš¡ Testing PARALLEL execution mode")
                print()
            
            # requestsãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            response = requests.post(
                self.runtime_url,
                data=payload_json,
                headers=headers,
                auth=self.auth,
                stream=True,
                timeout=300
            )
            
            if response.status_code != 200:
                raise Exception(f"HTTP {response.status_code}: {response.text}")
            
            print("âœ… Connection established, receiving parallel stream...")
            print()
            
            # Server-Sent Eventsã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å‡¦ç†
            for parsed_event in self._process_sse_stream(response):
                self._handle_event(parsed_event)
            
            self.stats["end_time"] = datetime.now()
            
            # ä¸¦åˆ—å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
            if self.stats["first_sage_start"] and self.stats["last_sage_complete"]:
                self.stats["parallel_execution_time"] = \
                    (self.stats["last_sage_complete"] - self.stats["first_sage_start"]).total_seconds()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            self._save_streams()
            
            # ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
            self._print_summary()
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ
            self._compare_performance()
            
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()
    
    def _process_sse_stream(self, response):
        """
        Server-Sent Eventsã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å‡¦ç†
        
        Args:
            response: requests.Responseã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            
        Yields:
            Dict[str, Any]: ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆ
        """
        buffer = ""
        chunk_count = 0
        
        try:
            if self.verbose:
                print("ğŸ” Processing parallel Server-Sent Events stream...")
                print()
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¡Œã”ã¨ã«å‡¦ç†
            for line in response.iter_lines(decode_unicode=True):
                chunk_count += 1
                
                if line:
                    buffer += line + '\n'
                else:
                    # ç©ºè¡Œã¯ã‚¤ãƒ™ãƒ³ãƒˆåŒºåˆ‡ã‚Š
                    if buffer.strip():
                        parsed_event = self._parse_sse_event(buffer)
                        if parsed_event:
                            yield parsed_event
                        buffer = ""
            
            # æ®‹ã‚Šã®ãƒãƒƒãƒ•ã‚¡ã‚’å‡¦ç†
            if buffer.strip():
                parsed_event = self._parse_sse_event(buffer)
                if parsed_event:
                    yield parsed_event
            
            if self.verbose:
                print(f"\nğŸ“¦ Total chunks processed: {chunk_count}")
                    
        except Exception as e:
            print(f"âš ï¸  SSE stream processing error: {e}")
            import traceback
            traceback.print_exc()
    
    def _parse_sse_event(self, event_text: str) -> Dict[str, Any]:
        """
        SSEã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹
        
        Args:
            event_text: SSEã‚¤ãƒ™ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            Dict[str, Any]: ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆ
        """
        lines = event_text.strip().split('\n')
        
        for line in lines:
            if line.startswith('data:'):
                data_text = line[5:].strip()
                try:
                    parsed = json.loads(data_text)
                    # æ–°ã—ã„å½¢å¼: {"type": "...", "data": {...}}
                    if isinstance(parsed, dict) and 'type' in parsed and 'data' in parsed:
                        return {
                            "type": parsed['type'],
                            "data": parsed['data'],
                            "timestamp": datetime.now().isoformat()
                        }
                    # å¤ã„å½¢å¼ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
                    return {
                        "type": "unknown",
                        "data": parsed,
                        "timestamp": datetime.now().isoformat()
                    }
                except json.JSONDecodeError:
                    pass
        
        return None
    
    def _handle_event(self, event: Dict[str, Any]):
        """
        ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†ï¼ˆä¸¦åˆ—å®Ÿè¡Œã®ç‰¹æ€§ã‚’è€ƒæ…®ï¼‰
        
        Args:
            event: ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿
        """
        self.stats["total_events"] += 1
        
        event_type = event.get("type")
        event_data = event.get("data", {})
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—çµ±è¨ˆ
        self.stats["events_by_type"][event_type] = \
            self.stats["events_by_type"].get(event_type, 0) + 1
        
        # å…¨ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²
        self.all_events.append(event)
        
        # ä¸¦åˆ—å®Ÿè¡Œæ™‚é–“æ¸¬å®š
        if event_type == "sage_start" and self.stats["first_sage_start"] is None:
            self.stats["first_sage_start"] = datetime.now()
        
        if event_type == "sage_complete":
            self.stats["last_sage_complete"] = datetime.now()
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã”ã¨ã®å‡¦ç†
        if event_type == "start":
            if self.verbose:
                print(f"ğŸš€ MAGI Parallel Decision Process Started")
                print(f"   Trace ID: {event_data.get('trace_id')}")
                print()
        
        elif event_type == "sage_start":
            agent_id = event_data.get("agent_id")
            if self.verbose:
                print(f"ğŸ¤– {agent_id.upper()} started thinking (PARALLEL)...")
        
        elif event_type == "sage_thinking":
            agent_id = event_data.get("agent_id")
            chunk = event_data.get("chunk", "")
            
            # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºï¼ˆä¸¦åˆ—å®Ÿè¡Œã‚’å¼·èª¿ï¼‰
            if self.verbose:
                print(f"   ğŸ’­ [{agent_id.upper()}] {chunk}", end='', flush=True)
        
        elif event_type == "sage_chunk":
            agent_id = event_data.get("agent_id")
            chunk = event_data.get("chunk", "")
            
            # ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
            self.streams[agent_id].append(chunk)
            self.stats["chunks_by_agent"][agent_id] += 1
            
            if self.verbose:
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºï¼ˆä¸¦åˆ—å®Ÿè¡Œã‚’å¼·èª¿ï¼‰
                print(f"   ğŸ’­ [{agent_id.upper()}] {chunk}")
        
        elif event_type == "sage_complete":
            agent_id = event_data.get("agent_id")
            decision = event_data.get("decision")
            confidence = event_data.get("confidence")
            reasoning = event_data.get("reasoning", "")
            
            if self.verbose:
                print(f"\n   âœ… [{agent_id.upper()}] {decision} (confidence: {confidence:.2f})")
                print(f"      Reasoning: {reasoning}")
                print()
        
        elif event_type == "sage_error":
            agent_id = event_data.get("agent_id")
            error = event_data.get("error")
            if self.verbose:
                print(f"   âŒ [{agent_id.upper()}] error: {error}")
                print()
        
        elif event_type == "judge_start":
            if self.verbose:
                print(f"\nâš–ï¸  SOLOMON Judge started evaluation...")
                print()
        
        elif event_type == "judge_thinking":
            chunk = event_data.get("chunk", "")
            
            # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
            if self.verbose:
                print(f"   ğŸ’­ [SOLOMON] {chunk}", end='', flush=True)
        
        elif event_type == "judge_chunk":
            chunk = event_data.get("chunk", "")
            
            # SOLOMONã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
            self.streams["solomon"].append(chunk)
            self.stats["chunks_by_agent"]["solomon"] += 1
            
            # é€²æ—è¡¨ç¤º
            preview = chunk[:50].replace('\n', ' ')
            print(f"   ğŸ’­ [SOLOMON] {preview}{'...' if len(chunk) > 50 else ''}")
        
        elif event_type == "judge_complete":
            final_decision = event_data.get("final_decision")
            confidence = event_data.get("confidence")
            
            print(f"   âœ… [SOLOMON] {final_decision} (confidence: {confidence:.2f})")
            print()
        
        elif event_type == "complete":
            final_decision = event_data.get("final_decision")
            voting_result = event_data.get("voting_result", {})
            execution_time = event_data.get("execution_time")
            
            print(f"ğŸ‰ MAGI Parallel Decision Complete!")
            print(f"   Final Decision: {final_decision}")
            print(f"   Voting: {voting_result.get('approved')}å¯æ±º / {voting_result.get('rejected')}å¦æ±º")
            print(f"   Total Time: {execution_time}ms")
            print()
        
        elif event_type == "error":
            error = event_data.get("error")
            print(f"âŒ Error: {error}")
            print()
    
    def _save_streams(self):
        """
        ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        """
        print("=" * 80)
        print("ğŸ’¾ Saving parallel streams to files...")
        print("=" * 80)
        
        # å„è³¢è€…ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä¿å­˜
        for agent_id, chunks in self.streams.items():
            if chunks:
                filename = self.output_dir / f"{agent_id}_stream.txt"
                
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(f"# {agent_id.upper()} Stream (PARALLEL)\n")
                    f.write(f"# Generated: {datetime.now().isoformat()}\n")
                    f.write(f"# Total Chunks: {len(chunks)}\n")
                    f.write("=" * 80 + "\n\n")
                    
                    full_text = ''.join(chunks)
                    f.write(full_text)
                
                print(f"âœ… Saved {agent_id}_stream.txt ({len(chunks)} chunks, {len(full_text)} chars)")
        
        # å…¨ã‚¤ãƒ™ãƒ³ãƒˆã‚’JSONã§ä¿å­˜
        events_file = self.output_dir / "full_stream.json"
        with open(events_file, 'w', encoding='utf-8') as f:
            json.dump(self.all_events, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Saved full_stream.json ({len(self.all_events)} events)")
        
        # ãƒ•ãƒ«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ä¿å­˜
        full_response_file = self.output_dir / "full_response_ordered.txt"
        with open(full_response_file, 'w', encoding='utf-8') as f:
            f.write("# Full Response (Parallel Execution - Ordered by Arrival Time)\n")
            f.write(f"# Generated: {datetime.now().isoformat()}\n")
            f.write("=" * 80 + "\n\n")
            
            for i, event in enumerate(self.all_events, 1):
                f.write(f"[Event {i}] {event.get('timestamp')}\n")
                f.write(f"Type: {event.get('type')}\n")
                f.write(f"Data: {json.dumps(event.get('data', {}), ensure_ascii=False, indent=2)}\n")
                f.write("-" * 80 + "\n\n")
        
        print(f"âœ… Saved full_response_ordered.txt ({len(self.all_events)} events)")
        
        # ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜
        self._save_summary()
        
        print()
    
    def _save_summary(self):
        """
        ã‚µãƒãƒªãƒ¼ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        """
        summary_file = self.output_dir / "summary.txt"
        
        duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()
        parallel_time = self.stats.get("parallel_execution_time", 0)
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("# MAGI Parallel Streaming Test Summary\n")
            f.write("=" * 80 + "\n\n")
            
            f.write(f"Test Time: {self.stats['start_time'].isoformat()}\n")
            f.write(f"Total Duration: {duration:.2f} seconds\n")
            f.write(f"Parallel Execution Time: {parallel_time:.2f} seconds\n")
            f.write(f"Total Events: {self.stats['total_events']}\n\n")
            
            f.write("## Events by Type\n")
            for event_type, count in sorted(self.stats["events_by_type"].items()):
                f.write(f"  {event_type}: {count}\n")
            f.write("\n")
            
            f.write("## Chunks by Agent\n")
            for agent_id, count in self.stats["chunks_by_agent"].items():
                f.write(f"  {agent_id}: {count} chunks\n")
            f.write("\n")
            
            f.write("## Stream Sizes\n")
            for agent_id, chunks in self.streams.items():
                if chunks:
                    total_chars = len(''.join(chunks))
                    f.write(f"  {agent_id}: {total_chars} characters\n")
            f.write("\n")
            
            f.write("## Files Generated\n")
            for agent_id in self.streams.keys():
                if self.streams[agent_id]:
                    f.write(f"  - {agent_id}_stream.txt\n")
            f.write(f"  - full_stream.json\n")
            f.write(f"  - full_response_ordered.txt\n")
            f.write(f"  - summary.txt\n")
        
        print(f"âœ… Saved summary.txt")
    
    def _print_summary(self):
        """
        ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        """
        print("=" * 80)
        print("ğŸ“Š Parallel Test Summary")
        print("=" * 80)
        
        duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()
        parallel_time = self.stats.get("parallel_execution_time", 0)
        
        print(f"Total Duration: {duration:.2f} seconds")
        print(f"Parallel Execution Time: {parallel_time:.2f} seconds")
        print(f"Total Events: {self.stats['total_events']}")
        print()
        
        print("Events by Type:")
        for event_type, count in sorted(self.stats["events_by_type"].items()):
            print(f"  {event_type}: {count}")
        print()
        
        print("Chunks by Agent:")
        for agent_id, count in self.stats["chunks_by_agent"].items():
            print(f"  {agent_id}: {count} chunks")
        print()
        
        print("Stream Sizes:")
        for agent_id, chunks in self.streams.items():
            if chunks:
                total_chars = len(''.join(chunks))
                print(f"  {agent_id}: {total_chars} characters")
        print()
        
        print(f"Output Directory: {self.output_dir.absolute()}")
        print("=" * 80)
    
    def _compare_performance(self):
        """
        ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒï¼ˆé€æ¬¡ç‰ˆã¨ã®æ¯”è¼ƒï¼‰
        """
        # é€æ¬¡ç‰ˆã®ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        sequential_summary = Path(__file__).parent / "streaming_output_phase2" / "summary.txt"
        
        if not sequential_summary.exists():
            print("\nâš ï¸  Sequential version summary not found. Run test_magi2.py first for comparison.")
            return
        
        try:
            with open(sequential_summary, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # å®Ÿè¡Œæ™‚é–“ã‚’æŠ½å‡º
            import re
            match = re.search(r'Duration: ([\d.]+) seconds', content)
            if match:
                sequential_time = float(match.group(1))
                parallel_time = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()
                
                improvement = ((sequential_time - parallel_time) / sequential_time) * 100
                speedup = sequential_time / parallel_time
                
                print("\n" + "=" * 80)
                print("âš¡ Performance Comparison")
                print("=" * 80)
                print(f"Sequential Version: {sequential_time:.2f} seconds")
                print(f"Parallel Version:   {parallel_time:.2f} seconds")
                print(f"Improvement:        {improvement:.1f}% faster")
                print(f"Speedup:            {speedup:.2f}x")
                print("=" * 80)
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                comparison_file = self.output_dir / "performance_comparison.txt"
                with open(comparison_file, 'w', encoding='utf-8') as f:
                    f.write("# Performance Comparison: Sequential vs Parallel\n")
                    f.write("=" * 80 + "\n\n")
                    f.write(f"Sequential Version: {sequential_time:.2f} seconds\n")
                    f.write(f"Parallel Version:   {parallel_time:.2f} seconds\n")
                    f.write(f"Improvement:        {improvement:.1f}% faster\n")
                    f.write(f"Speedup:            {speedup:.2f}x\n\n")
                    
                    if speedup >= 2.5:
                        f.write("âœ… EXCELLENT: Achieved near-optimal parallel speedup!\n")
                    elif speedup >= 2.0:
                        f.write("âœ… GOOD: Significant performance improvement!\n")
                    elif speedup >= 1.5:
                        f.write("âš ï¸  MODERATE: Some improvement, but room for optimization.\n")
                    else:
                        f.write("âŒ POOR: Parallel execution not providing expected benefits.\n")
                
                print(f"\nâœ… Saved performance_comparison.txt")
                
        except Exception as e:
            print(f"\nâš ï¸  Could not compare performance: {e}")


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    # è¨­å®šèª­ã¿è¾¼ã¿
    import sys
    from pathlib import Path
    sys.path.append(str(Path(__file__).parent.parent))
    from shared.config import get_config
    
    config = get_config()
    agent_arn = config.get_agent_arn()
    
    # AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³
    region = os.environ.get('AWS_REGION', 'ap-northeast-1')
    
    # ãƒ†ã‚¹ãƒˆè³ªå•
    test_question = "æ–°ã—ã„AIã‚·ã‚¹ãƒ†ãƒ ã‚’å…¨ç¤¾ã«å°å…¥ã™ã¹ãã‹ï¼Ÿã‚³ã‚¹ãƒˆå‰Šæ¸›ã¨åŠ¹ç‡åŒ–ãŒæœŸå¾…ã•ã‚Œã‚‹ãŒã€å¾“æ¥­å“¡ã®åç™ºã‚‚äºˆæƒ³ã•ã‚Œã‚‹ã€‚"
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¨­å®š
    verbose = os.environ.get('DEBUG_STREAMING', 'true').lower() == 'true'
    
    # ãƒ†ã‚¹ã‚¿ãƒ¼åˆæœŸåŒ–
    tester = ParallelStreamingTester(agent_arn, region, verbose=verbose)
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tester.test_streaming(test_question)


if __name__ == "__main__":
    main()
