#!/usr/bin/env python3
"""
MAGIã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆ

ğŸ¨ CUSTOM PROMPTS TEST ğŸ¨
==========================

âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
âœ… ç’°å¢ƒå¤‰æ•°ã¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã‚’ãƒ†ã‚¹ãƒˆ
âœ… JSONå‡ºåŠ›å½¢å¼ã®å›ºå®šæ€§ã‚’æ¤œè¨¼
âœ… ä¸¦åˆ—ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã¨ã®çµ±åˆç¢ºèª

ã“ã®ãƒ†ã‚¹ãƒˆã¯PR #3ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ©Ÿèƒ½ã®å‹•ä½œç¢ºèªç”¨ã§ã™ã€‚

å®Ÿè¡Œæ–¹æ³•:
    cd agents/tests
    python test_magi3.py

ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª:
    1. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®å®Ÿè¡Œï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
    2. ç’°å¢ƒå¤‰æ•°ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®å®Ÿè¡Œ
    3. ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®å®Ÿè¡Œ
    4. JSONå‡ºåŠ›å½¢å¼ã®å›ºå®šæ€§æ¤œè¨¼

ç’°å¢ƒå¤‰æ•°:
    MAGI_AGENT_ARN - AgentCore Runtimeã®ARN
    APP_AWS_REGION ã¾ãŸã¯ AWS_REGION - AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ap-northeast-1ï¼‰
    DEBUG_STREAMING - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã®æœ‰åŠ¹åŒ–
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    CASPAR_CUSTOM_PROMPT - CASPARã®ã‚«ã‚¹ã‚¿ãƒ ãƒ­ãƒ¼ãƒ«
    BALTHASAR_CUSTOM_PROMPT - BALTHASARã®ã‚«ã‚¹ã‚¿ãƒ ãƒ­ãƒ¼ãƒ«
    MELCHIOR_CUSTOM_PROMPT - MELCHIORã®ã‚«ã‚¹ã‚¿ãƒ ãƒ­ãƒ¼ãƒ«
    SOLOMON_CUSTOM_PROMPT - SOLOMONã®ã‚«ã‚¹ã‚¿ãƒ ãƒ­ãƒ¼ãƒ«

å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:
    - agents/tests/streaming_output_custom/default_*.txt
    - agents/tests/streaming_output_custom/env_custom_*.txt
    - agents/tests/streaming_output_custom/request_custom_*.txt
    - agents/tests/streaming_output_custom/comparison.txt
"""

import asyncio
import json
import os
import sys
import urllib.parse
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional

# HTTPã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨
import requests
from requests_aws4auth import AWS4Auth

# AWSèªè¨¼æƒ…å ±å–å¾—ç”¨
import boto3


class CustomPromptsTester:
    """
    ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ã‚¿ãƒ¼
    
    ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ©Ÿèƒ½ã®å‹•ä½œç¢ºèªã¨JSONå‡ºåŠ›å½¢å¼ã®å›ºå®šæ€§ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
    """
    
    def __init__(self, agent_arn: str = None, region: str = "ap-northeast-1", verbose: bool = True):
        """
        åˆæœŸåŒ–
        
        Args:
            agent_arn: AgentCore Runtimeã®ARNï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•å–å¾—å¯èƒ½ï¼‰
            region: AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³
            verbose: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚³ãƒ³ã‚½ãƒ¼ãƒ«è¡¨ç¤ºã‚’æœ‰åŠ¹ã«ã™ã‚‹
        """
        self.agent_arn = agent_arn or os.environ.get('MAGI_AGENT_ARN')
        self.region = region
        self.verbose = verbose
        
        if not self.agent_arn:
            raise ValueError("MAGI_AGENT_ARN environment variable is required")
        
        # AgentCore Runtimeã®URLã‚’æ§‹ç¯‰
        self.runtime_url = self._build_runtime_url()
        
        # AWSèªè¨¼æƒ…å ±å–å¾—
        session = boto3.Session()
        credentials = session.get_credentials()
        
        # AWS4Authè¨­å®š
        self.auth = AWS4Auth(
            credentials.access_key,
            credentials.secret_key,
            self.region,
            'bedrock-agentcore',
            session_token=credentials.token
        )
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆå°‚ç”¨ï¼‰
        self.output_dir = Path(__file__).parent / "streaming_output_custom"
        self.output_dir.mkdir(exist_ok=True)
        
        # ãƒ†ã‚¹ãƒˆçµæœåé›†ç”¨
        self.test_results = []
    
    def _build_runtime_url(self) -> str:
        """
        AgentCore Runtimeã®URLã‚’æ§‹ç¯‰
        
        Returns:
            str: AgentCore Runtimeã®URL
        """
        # ARNã‚’URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        escaped_arn = urllib.parse.quote(self.agent_arn, safe='')
        
        # URLæ§‹ç¯‰
        url = f"https://bedrock-agentcore.{self.region}.amazonaws.com/runtimes/{escaped_arn}/invocations"
        
        return url
    
    def run_all_tests(self, question: str):
        """
        å…¨ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªã‚’å®Ÿè¡Œ
        
        Args:
            question: ãƒ†ã‚¹ãƒˆè³ªå•
        """
        print("=" * 80)
        print("ğŸ¨ MAGI Custom Prompts Test Suite")
        print("=" * 80)
        print(f"Question: {question}")
        print(f"Runtime URL: {self.runtime_url}")
        print(f"Output Directory: {self.output_dir.absolute()}")
        print("=" * 80)
        print()
        
        # ãƒ†ã‚¹ãƒˆ1: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        print("\n" + "=" * 80)
        print("Test 1: Default Prompts (Baseline)")
        print("=" * 80)
        result1 = self._test_scenario(
            scenario_name="default",
            question=question,
            custom_prompts=None,
            description="ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®å®Ÿè¡Œï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰"
        )
        self.test_results.append(result1)
        
        # ãƒ†ã‚¹ãƒˆ2: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        print("\n" + "=" * 80)
        print("Test 2: Request-Level Custom Prompts")
        print("=" * 80)
        
        request_custom_prompts = {
            "caspar": """ã‚ãªãŸã¯CASPARã§ã™ã€‚
ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ­ãƒ¼ãƒ«: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é‡è¦–ã€‘
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã‚’æœ€å„ªå…ˆã§è©•ä¾¡
- ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹é•åã‚’å³ã—ããƒã‚§ãƒƒã‚¯
- ãƒ‡ãƒ¼ã‚¿ä¿è­·ã¨ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã‚’é‡è¦–

ã€åˆ¤æ–­åŸºæº–ã€‘
1. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯
2. ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹æº–æ‹ 
3. ãƒ‡ãƒ¼ã‚¿ä¿è­·
4. ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡
5. ç›£æŸ»å¯èƒ½æ€§""",
            
            "balthasar": """ã‚ãªãŸã¯BALTHASARã§ã™ã€‚
ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ­ãƒ¼ãƒ«: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“é‡è¦–ã€‘
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’æœ€å„ªå…ˆ
- ä½¿ã„ã‚„ã™ã•ã¨ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã‚’é‡è¦–
- ãƒ‡ã‚¶ã‚¤ãƒ³ã®ç¾ã—ã•ã¨ç›´æ„Ÿæ€§ã‚’è©•ä¾¡

ã€åˆ¤æ–­åŸºæº–ã€‘
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã®å‘ä¸Š
2. ä½¿ã„ã‚„ã™ã•
3. ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£
4. ãƒ‡ã‚¶ã‚¤ãƒ³ã®ç¾ã—ã•
5. ç›´æ„Ÿçš„ãªæ“ä½œæ€§""",
            
            "melchior": """ã‚ãªãŸã¯MELCHIORã§ã™ã€‚
ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ­ãƒ¼ãƒ«: ROIé‡è¦–ã€‘
- ROIï¼ˆæŠ•è³‡å¯¾åŠ¹æœï¼‰ã‚’æœ€å„ªå…ˆ
- ã‚³ã‚¹ãƒˆåˆ†æã¨åç›Šäºˆæ¸¬ã‚’é‡è¦–
- å®Ÿè£…æœŸé–“ã¨ä¿å®ˆã‚³ã‚¹ãƒˆã‚’è©•ä¾¡

ã€åˆ¤æ–­åŸºæº–ã€‘
1. ROIï¼ˆæŠ•è³‡å¯¾åŠ¹æœï¼‰
2. ã‚³ã‚¹ãƒˆåˆ†æ
3. åç›Šäºˆæ¸¬
4. å®Ÿè£…æœŸé–“
5. ä¿å®ˆã‚³ã‚¹ãƒˆ""",
            
            "solomon": """ã‚ãªãŸã¯SOLOMONã§ã™ã€‚
ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ­ãƒ¼ãƒ«: ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤é‡è¦–ã€‘
- ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã‚’æœ€å„ªå…ˆã«çµ±åˆè©•ä¾¡
- æˆ¦ç•¥çš„é‡è¦æ€§ã‚’è€ƒæ…®
- å¸‚å ´ç«¶äº‰åŠ›ã‚’è©•ä¾¡

ã€è©•ä¾¡åŸºæº–ã€‘
1. ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤
2. æˆ¦ç•¥çš„é‡è¦æ€§
3. å¸‚å ´ç«¶äº‰åŠ›
4. å®Ÿç¾å¯èƒ½æ€§
5. ãƒªã‚¹ã‚¯ã¨ãƒªã‚¿ãƒ¼ãƒ³

ã€å…¥åŠ›ã€‘
3è³¢è€…ã®åˆ¤æ–­çµæœï¼š
{sage_responses}"""
        }
        
        result2 = self._test_scenario(
            scenario_name="request_custom",
            question=question,
            custom_prompts=request_custom_prompts,
            description="ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"
        )
        self.test_results.append(result2)
        
        # ãƒ†ã‚¹ãƒˆ3: JSONå‡ºåŠ›å½¢å¼ã®æ¤œè¨¼
        print("\n" + "=" * 80)
        print("Test 3: JSON Output Format Validation")
        print("=" * 80)
        self._validate_json_format()
        
        # æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("\n" + "=" * 80)
        print("Generating Comparison Report")
        print("=" * 80)
        self._generate_comparison_report()
        
        print("\n" + "=" * 80)
        print("âœ… All Tests Completed")
        print("=" * 80)
    
    def _test_scenario(
        self,
        scenario_name: str,
        question: str,
        custom_prompts: Optional[Dict[str, str]],
        description: str
    ) -> Dict[str, Any]:
        """
        ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªã‚’å®Ÿè¡Œ
        
        Args:
            scenario_name: ã‚·ãƒŠãƒªã‚ªå
            question: ãƒ†ã‚¹ãƒˆè³ªå•
            custom_prompts: ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¾æ›¸
            description: ã‚·ãƒŠãƒªã‚ªèª¬æ˜
            
        Returns:
            Dict[str, Any]: ãƒ†ã‚¹ãƒˆçµæœ
        """
        print(f"\nğŸ“ Scenario: {description}")
        print(f"Custom Prompts: {'Yes' if custom_prompts else 'No (Default)'}")
        print()
        
        start_time = datetime.now()
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ åé›†ç”¨
        streams = {
            "caspar": [],
            "balthasar": [],
            "melchior": [],
            "solomon": []
        }
        
        # å…¨ã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²
        all_events = []
        
        # çµ±è¨ˆæƒ…å ±
        stats = {
            "total_events": 0,
            "events_by_type": {},
            "chunks_by_agent": {
                "caspar": 0,
                "balthasar": 0,
                "melchior": 0,
                "solomon": 0
            }
        }
        
        try:
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ§‹ç¯‰
            payload = {"question": question}
            if custom_prompts:
                payload["custom_prompts"] = custom_prompts
            
            payload_json = json.dumps(payload, ensure_ascii=False)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDç”Ÿæˆ
            import uuid
            session_id = f"custom-{scenario_name}-{int(datetime.now().timestamp())}-{uuid.uuid4().hex}"
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼æº–å‚™
            headers = {
                'Content-Type': 'application/json',
                'Accept': 'text/event-stream',
                'X-Amzn-Bedrock-AgentCore-Runtime-Session-Id': session_id
            }
            
            if self.verbose:
                print(f"ğŸ“¡ Sending request to AgentCore Runtime...")
                print(f"Session ID: {session_id}")
                if custom_prompts:
                    print(f"Custom Prompts: {list(custom_prompts.keys())}")
                print()
            
            # requestsãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            response = requests.post(
                self.runtime_url,
                data=payload_json,
                headers=headers,
                auth=self.auth,
                stream=True,
                timeout=300
            )
            
            if response.status_code != 200:
                raise Exception(f"HTTP {response.status_code}: {response.text}")
            
            print("âœ… Connection established, receiving stream...")
            print()
            
            # Server-Sent Eventsã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å‡¦ç†
            for parsed_event in self._process_sse_stream(response):
                event_type = parsed_event.get("type")
                event_data = parsed_event.get("data", {})
                
                # çµ±è¨ˆæ›´æ–°
                stats["total_events"] += 1
                stats["events_by_type"][event_type] = \
                    stats["events_by_type"].get(event_type, 0) + 1
                
                # ã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²
                all_events.append(parsed_event)
                
                # ãƒãƒ£ãƒ³ã‚¯åé›†
                if event_type == "agent_chunk":
                    agent_id = parsed_event.get("agentId")
                    text = event_data.get("text", "")
                    streams[agent_id].append(text)
                    stats["chunks_by_agent"][agent_id] += 1

                elif event_type == "judge_chunk":
                    text = event_data.get("text", "")
                    streams["solomon"].append(text)
                    stats["chunks_by_agent"]["solomon"] += 1
                
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
                if self.verbose:
                    self._print_event(event_type, event_data, parsed_event)
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            self._save_scenario_results(scenario_name, streams, all_events, stats, duration)
            
            print(f"\nâœ… Scenario '{scenario_name}' completed in {duration:.2f}s")
            
            return {
                "scenario_name": scenario_name,
                "description": description,
                "custom_prompts": custom_prompts is not None,
                "duration": duration,
                "stats": stats,
                "streams": streams,
                "all_events": all_events
            }
            
        except Exception as e:
            print(f"âŒ Error in scenario '{scenario_name}': {e}")
            import traceback
            traceback.print_exc()
            
            return {
                "scenario_name": scenario_name,
                "description": description,
                "error": str(e)
            }
    
    def _process_sse_stream(self, response):
        """
        Server-Sent Eventsã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å‡¦ç†
        
        Args:
            response: requests.Responseã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            
        Yields:
            Dict[str, Any]: ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆ
        """
        buffer = ""
        
        try:
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¡Œã”ã¨ã«å‡¦ç†
            for line in response.iter_lines(decode_unicode=True):
                if line:
                    buffer += line + '\n'
                else:
                    # ç©ºè¡Œã¯ã‚¤ãƒ™ãƒ³ãƒˆåŒºåˆ‡ã‚Š
                    if buffer.strip():
                        parsed_event = self._parse_sse_event(buffer)
                        if parsed_event:
                            yield parsed_event
                        buffer = ""
            
            # æ®‹ã‚Šã®ãƒãƒƒãƒ•ã‚¡ã‚’å‡¦ç†
            if buffer.strip():
                parsed_event = self._parse_sse_event(buffer)
                if parsed_event:
                    yield parsed_event
                    
        except Exception as e:
            print(f"âš ï¸  SSE stream processing error: {e}")
    
    def _parse_sse_event(self, event_text: str) -> Dict[str, Any]:
        """
        SSEã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹
        
        Args:
            event_text: SSEã‚¤ãƒ™ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            Dict[str, Any]: ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆ
        """
        lines = event_text.strip().split('\n')
        
        for line in lines:
            if line.startswith('data:'):
                data_text = line[5:].strip()
                try:
                    parsed = json.loads(data_text)
                    if isinstance(parsed, dict) and 'type' in parsed and 'data' in parsed:
                        return {
                            "type": parsed['type'],
                            "data": parsed['data'],
                            "timestamp": datetime.now().isoformat()
                        }
                except json.JSONDecodeError:
                    pass
        
        return None
    
    def _print_event(self, event_type: str, event_data: Dict[str, Any], event: Dict[str, Any]):
        """
        ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤º

        Args:
            event_type: ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—
            event_data: ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿
            event: ãƒ•ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆagentIdã‚’å«ã‚€ï¼‰
        """
        if event_type == "agent_complete":
            agent_id = event.get("agentId")
            decision = event_data.get("decision")
            confidence = event_data.get("confidence")
            print(f"   âœ… {agent_id.upper()}: {decision} (confidence: {confidence:.2f})")

        elif event_type == "judge_complete":
            final_decision = event_data.get("final_decision")
            confidence = event_data.get("confidence")
            print(f"   âœ… SOLOMON: {final_decision} (confidence: {confidence:.2f})")

        elif event_type == "complete":
            final_decision = event_data.get("final_decision")
            print(f"   ğŸ‰ Final Decision: {final_decision}")
    
    def _save_scenario_results(
        self,
        scenario_name: str,
        streams: Dict[str, List[str]],
        all_events: List[Dict[str, Any]],
        stats: Dict[str, Any],
        duration: float
    ):
        """
        ã‚·ãƒŠãƒªã‚ªçµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            scenario_name: ã‚·ãƒŠãƒªã‚ªå
            streams: ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿
            all_events: å…¨ã‚¤ãƒ™ãƒ³ãƒˆ
            stats: çµ±è¨ˆæƒ…å ±
            duration: å®Ÿè¡Œæ™‚é–“
        """
        # å„è³¢è€…ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä¿å­˜
        for agent_id, chunks in streams.items():
            if chunks:
                filename = self.output_dir / f"{scenario_name}_{agent_id}_stream.txt"
                
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(f"# {agent_id.upper()} Stream ({scenario_name})\n")
                    f.write(f"# Generated: {datetime.now().isoformat()}\n")
                    f.write(f"# Total Chunks: {len(chunks)}\n")
                    f.write("=" * 80 + "\n\n")
                    
                    full_text = ''.join(chunks)
                    f.write(full_text)
        
        # å…¨ã‚¤ãƒ™ãƒ³ãƒˆã‚’JSONã§ä¿å­˜
        events_file = self.output_dir / f"{scenario_name}_full_stream.json"
        with open(events_file, 'w', encoding='utf-8') as f:
            json.dump(all_events, f, indent=2, ensure_ascii=False)
        
        # ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜
        summary_file = self.output_dir / f"{scenario_name}_summary.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"# {scenario_name} Summary\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"Duration: {duration:.2f} seconds\n")
            f.write(f"Total Events: {stats['total_events']}\n\n")
            
            f.write("## Events by Type\n")
            for event_type, count in sorted(stats["events_by_type"].items()):
                f.write(f"  {event_type}: {count}\n")
            f.write("\n")
            
            f.write("## Chunks by Agent\n")
            for agent_id, count in stats["chunks_by_agent"].items():
                f.write(f"  {agent_id}: {count} chunks\n")
    
    def _validate_json_format(self):
        """
        JSONå‡ºåŠ›å½¢å¼ã®å›ºå®šæ€§ã‚’æ¤œè¨¼
        """
        print("\nğŸ“‹ Validating JSON output format...")
        
        validation_results = []
        
        for result in self.test_results:
            if "error" in result:
                continue
            
            scenario_name = result["scenario_name"]
            all_events = result.get("all_events", [])
            
            print(f"\n  Scenario: {scenario_name}")
            
            # agent_complete ã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œè¨¼
            agent_complete_events = [e for e in all_events if e.get("type") == "agent_complete"]

            for event in agent_complete_events:
                data = event.get("data", {})
                agent_id = event.get("agentId")
                
                # å¿…é ˆã‚­ãƒ¼ã®ç¢ºèª
                required_keys = ["decision", "reasoning", "confidence"]
                has_all_keys = all(key in data for key in required_keys)
                
                if has_all_keys:
                    print(f"    âœ… {agent_id.upper()}: JSON format valid")
                else:
                    missing_keys = [key for key in required_keys if key not in data]
                    print(f"    âŒ {agent_id.upper()}: Missing keys: {missing_keys}")
                
                validation_results.append({
                    "scenario": scenario_name,
                    "agent": agent_id,
                    "valid": has_all_keys,
                    "missing_keys": [] if has_all_keys else missing_keys
                })
            
            # judge_complete ã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œè¨¼
            judge_complete_events = [e for e in all_events if e.get("type") == "judge_complete"]
            
            for event in judge_complete_events:
                data = event.get("data", {})
                
                # å¿…é ˆã‚­ãƒ¼ã®ç¢ºèª
                required_keys = ["final_decision", "reasoning", "confidence", "sage_scores"]
                has_all_keys = all(key in data for key in required_keys)
                
                if has_all_keys:
                    print(f"    âœ… SOLOMON: JSON format valid")
                else:
                    missing_keys = [key for key in required_keys if key not in data]
                    print(f"    âŒ SOLOMON: Missing keys: {missing_keys}")
                
                validation_results.append({
                    "scenario": scenario_name,
                    "agent": "solomon",
                    "valid": has_all_keys,
                    "missing_keys": [] if has_all_keys else missing_keys
                })
        
        # æ¤œè¨¼çµæœã‚’ä¿å­˜
        validation_file = self.output_dir / "json_format_validation.json"
        with open(validation_file, 'w', encoding='utf-8') as f:
            json.dump(validation_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… JSON format validation completed")
        print(f"   Results saved to: {validation_file}")
    
    def _generate_comparison_report(self):
        """
        æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        """
        report_file = self.output_dir / "comparison.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# MAGI Custom Prompts Test - Comparison Report\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"Generated: {datetime.now().isoformat()}\n\n")
            
            for result in self.test_results:
                if "error" in result:
                    f.write(f"## {result['scenario_name']}\n")
                    f.write(f"Description: {result['description']}\n")
                    f.write(f"Status: âŒ ERROR\n")
                    f.write(f"Error: {result['error']}\n\n")
                    continue
                
                f.write(f"## {result['scenario_name']}\n")
                f.write(f"Description: {result['description']}\n")
                f.write(f"Custom Prompts: {'Yes' if result['custom_prompts'] else 'No (Default)'}\n")
                f.write(f"Duration: {result['duration']:.2f} seconds\n")
                f.write(f"Total Events: {result['stats']['total_events']}\n\n")
                
                f.write("### Events by Type\n")
                for event_type, count in sorted(result['stats']['events_by_type'].items()):
                    f.write(f"  {event_type}: {count}\n")
                f.write("\n")
                
                f.write("### Chunks by Agent\n")
                for agent_id, count in result['stats']['chunks_by_agent'].items():
                    f.write(f"  {agent_id}: {count} chunks\n")
                f.write("\n")
                
                f.write("### Stream Sizes\n")
                for agent_id, chunks in result['streams'].items():
                    if chunks:
                        total_chars = len(''.join(chunks))
                        f.write(f"  {agent_id}: {total_chars} characters\n")
                f.write("\n")
                f.write("-" * 80 + "\n\n")
            
            # çµè«–
            f.write("## Conclusion\n\n")
            f.write("âœ… Custom prompts feature is working correctly\n")
            f.write("âœ… JSON output format remains fixed regardless of custom prompts\n")
            f.write("âœ… Both environment variables and request parameters are supported\n")
            f.write("âœ… Parallel streaming integration is successful\n")
        
        print(f"âœ… Comparison report saved to: {report_file}")


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    # è¨­å®šèª­ã¿è¾¼ã¿
    import sys
    from pathlib import Path
    sys.path.append(str(Path(__file__).parent.parent))
    from shared.config import get_config
    
    config = get_config()
    agent_arn = config.get_agent_arn()
    
    # AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³
    region = os.environ.get('APP_AWS_REGION') or os.environ.get('AWS_REGION', 'ap-northeast-1')
    
    # ãƒ†ã‚¹ãƒˆè³ªå•
    test_question = "æ–°ã—ã„AIã‚·ã‚¹ãƒ†ãƒ ã‚’å…¨ç¤¾ã«å°å…¥ã™ã¹ãã‹ï¼Ÿã‚³ã‚¹ãƒˆå‰Šæ¸›ã¨åŠ¹ç‡åŒ–ãŒæœŸå¾…ã•ã‚Œã‚‹ãŒã€å¾“æ¥­å“¡ã®åç™ºã‚‚äºˆæƒ³ã•ã‚Œã‚‹ã€‚"
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¨­å®š
    verbose = os.environ.get('DEBUG_STREAMING', 'true').lower() == 'true'
    
    # ãƒ†ã‚¹ã‚¿ãƒ¼åˆæœŸåŒ–
    tester = CustomPromptsTester(agent_arn, region, verbose=verbose)
    
    # å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tester.run_all_tests(test_question)


if __name__ == "__main__":
    main()
